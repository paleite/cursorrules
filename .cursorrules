# .cursorrules

This document provides comprehensive guidance for development with Cursor's Composer, focusing on best practices for Next.js, React (TypeScript), Tailwind CSS + ShadCN, Zod, and react-query.

## Core Technical Mandates

**USE**:

- **react-query** for async data fetching and caching (instead of `useEffect` + `fetch`).
- **Zod** to validate **all** API responses and form inputs.
- **Tailwind CSS + ShadCN/UI + `cn()`** for styling and class composition.
- **react-hook-form** for all form handling.
- **Zustand** for non-context or persistent client-side state.
- **@ebay/nice-modal-react** for modals.

**AVOID**:

- `useEffect` for data fetching.
- `fetch()` directly; use a dedicated hook or API client instead.
- Inline styles; rely on Tailwind classes or `class-variance-authority`.
- Mutating data and `for`-loops; favor immutability and array methods (`map`, `filter`, etc.).
- String concatenation to build class names; use the `cn()` utility.
- Default exports (except in Next.js pages).

## Working with Cursor Composer

### Before You Start

- **Figure out which rules apply to the feature you're implementing.**
  For example, if the feature involves data fetching, highlight rules about using `react-query` (and not `useEffect` or `fetch`). If it needs forms, refer to **react-hook-form** and **Zod**.

- **Repeat the relevant rules in your response.**
  This ensures transparency; the user will see which `.cursorrules` items you're following (and how).

### Large Feature Implementation Guidelines

These guidelines detail how to plan, implement, and finalize features while **chunking** tasks for **Cursor's Composer**. The goal is to avoid exceeding the LLM context window and to handle **big** features incrementally.

#### 1. Planning Phase

1. **Check `progress.md`** for a corresponding feature section.

   - If none exists, create an outline in `[ ]` checklist format covering:
     - Feature scope & expected behavior.
     - Key components/modules to add or modify.
     - Filenames to create or change (and what they should contain).
     - Dependencies or prerequisite steps.
     - Potential edge cases & error handling.
     - Adherence to `.cursorrules` (Zod validations, react-query, tailwind, syntax & style, file structure, etc.).

2. **Define the High-Level Feature**

   - Clearly articulate what the feature needs to do and any constraints (like design specs or acceptance criteria).

3. **Chunk the Feature**
   - If the request is too large to fit into the LLM's context, break it into smaller tasks or subtasks.
   - Label each subtask (e.g., "Subtask 1 of 5").
   - This is like splitting an EDM set into multiple smaller segmentsâ€”each one has its own distinct focus, but they form a unified whole.

#### 2. Implementation Phase

1. **Work on a Single Chunk**

   - For each subtask, pass any relevant code snippets or references to Cursor.
   - If multiple files are affected, focus on smaller sections of code in each iteration.

2. **Context Carryover**

   - Remind Cursor what was done in previous chunks.
   - If Cursor "forgets," re-supply the necessary code or instructions from the previous step.

3. **Feedback Loops**

   - After generating code for each chunk, review it.
   - If errors or inconsistencies appear, correct them or clarify your instructions.
   - Confirm or reject each subtask's output before moving on.

4. **Keep `progress.md` Updated**
   - Check off finished tasks, add notes or revisions as needed.

#### 3. Review & Documentation Phase

1. **Testing and Validation**

   - After each chunk or once the chunk is completed, run tests or do a manual check.
   - Fix issues in the code, either manually or by prompting Cursor.
   - For new or existing code, write or update relevant unit tests, integration tests, etc.

2. **Update Project Docs**

   - Document changes in `CHANGELOG.md`.
   - If your code has any complex logic or custom hooks, add inline comments or short usage docs.

3. **Confirm the Feature Meets the Outlined Goals**
   - Cross-check with the initial plan (in `progress.md`) to ensure no steps or edge cases are missed.

#### 4. Finalization & Commit

1. **Integrate Changes**

   - Once all chunks are approved, unify them into the feature branch or main branch (depending on your branching strategy).

2. **Final Test & Code Review**

   - Do a final pass for formatting (ESLint, Prettier), project conventions, and run `typecheck` if applicable.

3. **Post Summary**
   - In `progress.md`, note that the feature is complete and reference any relevant PR or commit hashes.

### Additional Cursor Composer Guidance

1. **Short Context Window**

   - Acknowledge that Cursor's context window has limits. For large code sections, break them into smaller snippets when you prompt.

2. **New vs. Existing Codebases**

   - These chunking and carryover rules apply equally whether you're introducing a brand-new feature or modifying an established codebase.

3. **Resilient to Mistakes**

   - The LLM can introduce errors. Use iterative feedback loops: generate code, then review and correct.

4. **Adhere to Project Decisions**

   - Always remember to use the frameworks, libraries, and style decisions listed in "Core Technical Mandates."

5. **User Confirmation**
   - After each subtask, prompt for user feedback or additional clarifications.

## Project Structure and Organization

### File Structure

- **kebab-case** for filenames.
- **`.tsx`** for TypeScript with JSX; **`.ts`** otherwise.
- Test files: `[filename].test.ts` or `[filename].test.tsx`.

### Folder Structure

```
src/
  app/  // The Next.js app structure (pages, layouts, etc.)
    users/  // Feature-specific files for the "users" feature
      page.ts // Imports the CreateUserForm
      create-user-form.tsx  // Exports a component using react-hook-form
      use-create-user-modal.tsx // Exports a hook from @ebay/nice-modal-react
  components/ // React components
    ui/ // Reusable UI components (e.g., ShadCN components)
    common/ // Reusable across multiple features
    form-input/ // Standard form input components
  contexts/ // React context providers
    auth-context.ts
    user-context.ts
  lib/  // Project-level libraries/utilities
    api.ts
    constants.ts
    postchain-client.ts
    utils/  // Generic utility functions
      format.ts
      convert.ts
  hooks/  // Global React hooks
  providers/  // React context providers
    auth-provider.ts
    user-provider.ts
  queries/  // React Query queries/mutations
    users-queries.ts
    posts-queries.ts
  schemas/  // Zod schemas
    user-schema.ts
    product-schema.ts
  stores/ // Zustand or other state management
    user-store.ts
    settings-store.ts
  forms/ // Form components organized by entity
```

### Exports and Imports

- Remove unused exports regularly.
- Export next to declarations; avoid placing all exports at the file bottom.
- Avoid default exports (except in Next.js pages).
- Import with short paths (e.g., `@/components/ui`) and prefer `@/*` from the project root.
- Keep import paths as concise as possible.

### Static Export Considerations

- When building for static export, avoid server components, middleware, and other server-side features.
- Use query parameters instead of dynamic routes for data filtering and selection.
- All dynamic data must be fetched client-side after route hydration.
- Ensure all components work properly in a static export environment.
- Use `next.config.ts` to configure static export settings properly.

### Next.js Deployment Configuration

- **Always set `basePath` when deploying to non-root paths**:
  ```typescript
  // For production environments with subpath deployment
  export const basePath = 
    process.env.NODE_ENV === "production" 
      ? `/your_app_path/${process.env.DEPLOYMENT_ID}/static` 
      : "";
  
  const nextConfig: NextConfig = {
    basePath,
    // other config...
  };
  ```

- **Configure static exports correctly**:
  ```typescript
  const nextConfig: NextConfig = {
    output: "export",
    images: {
      unoptimized: true, // Required for static exports
    },
    // other config...
  };
  ```

- **Handle redirects conditionally for development vs. static export**:
  ```typescript
  ...(process.env.NODE_ENV === "development"
    ? {
        // Redirects only in development
        redirects: async () => [
          {
            source: "/docs",
            destination: env.NEXT_PUBLIC_DOCS_URL,
            permanent: true,
          },
        ],
      }
    : {
        // Static export configuration for production
        output: "export",
      }),
  ```

- **GitHub Pages Deployment Workflow**:
  For deploying Next.js sites to GitHub Pages, use a workflow like this:
  ```yaml
  name: Deploy Next.js site to Pages

  on:
    push:
      branches: ["main"]
    workflow_dispatch:

  permissions:
    contents: read
    pages: write
    id-token: write

  concurrency:
    group: "pages"
    cancel-in-progress: false

  jobs:
    build:
      runs-on: ubuntu-latest
      steps:
        - name: Checkout
          uses: actions/checkout@v4

        - name: Setup Node.js
          uses: actions/setup-node@v4
          with:
            node-version-file: ".nvmrc"

        - name: Enable Corepack
          run: corepack enable

        - name: Setup Pages
          uses: actions/configure-pages@v5
          with:
            # Automatically injects basePath for GitHub Pages
            static_site_generator: next

        - name: Get pnpm store directory
          shell: bash
          run: |
            echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_ENV

        - uses: actions/cache@v4
          name: Setup pnpm cache
          with:
            path: ${{ env.STORE_PATH }}
            key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
            restore-keys: |
              ${{ runner.os }}-pnpm-store-

        - name: Restore Next.js cache
          uses: actions/cache@v4
          with:
            path: |
              .next/cache
            key: ${{ runner.os }}-nextjs-${{ hashFiles('**/pnpm-lock.yaml') }}-${{ hashFiles('**.[jt]s', '**.[jt]sx') }}
            restore-keys: |
              ${{ runner.os }}-nextjs-${{ hashFiles('**/pnpm-lock.yaml') }}-

        - name: Install dependencies
          run: pnpm install

        - name: Build with Next.js
          run: pnpm next build

        - name: Upload artifact
          uses: actions/upload-pages-artifact@v3
          with:
            path: ./out

    deploy:
      environment:
        name: github-pages
        url: ${{ steps.deployment.outputs.page_url }}
      runs-on: ubuntu-latest
      needs: build
      steps:
        - name: Deploy to GitHub Pages
          id: deployment
          uses: actions/deploy-pages@v4
  ```
  The `actions/configure-pages@v5` action with `static_site_generator: next` automatically:
  - Injects the correct `basePath` for GitHub Pages
  - Disables server-side image optimization

## Development Standards

### Code Readability

- Prioritize **readability** over conciseness.
- Maintain **consistent naming**.
- Use **descriptive names** for functions, variables, and booleans (e.g., `isUserAuthenticated()`).
- Rename identifiers if their purpose changes.
- **When generating new code**:
  - Prefer **explicit** syntax over shorthand.
  - Example: `React.FunctionComponent` instead of `React.FC`, `disabled={true}` instead of just `disabled`.
- Comment and document any workarounds or suboptimal solutions.
- Break large functions into smaller, testable ones.
- Prefer early returns to reduce nesting.
- Avoid magic numbers; use named constants.
- Use capital letters for constants.

### Code Formatting

- Configure Prettier with Tailwind plugin for consistent class ordering:
  ```js
  // prettier.config.js or .prettierrc.js
  module.exports = {
    plugins: ["prettier-plugin-tailwindcss"],
    tailwindFunctions: ["cva", "cn"],
  };
  ```
- This ensures Tailwind classes follow the recommended sort order
- Also preserves class ordering in `cva` and `cn` function calls
- Run format checks during CI and as pre-commit hooks
- Maintain consistent indentation and line endings

### Pre-commit Hooks with Husky

Set up Husky to run linting and formatting before each commit:

#### Installation and Setup

```bash
# Install Husky and related tools
pnpm add -D husky lint-staged pretty-quick

# Configure husky
pnpm exec husky init
```

#### Configuration by Package Manager

**For pnpm projects** (recommended):
```sh
#!/usr/bin/env sh
. "$(dirname -- "$0")/_/husky.sh"

# Run type checking first to catch type errors
pnpm run typecheck

# Run formatting and linting
$(pnpm bin)/pretty-quick --staged
$(pnpm bin)/lint-staged
```

**For npm projects**:
```sh
#!/usr/bin/env sh
. "$(dirname -- "$0")/_/husky.sh"

# Run type checking first
npm run typecheck

# Run formatting and linting
npx --no-install pretty-quick --staged
npx --no-install lint-staged
```

**For Yarn projects**:
```sh
#!/usr/bin/env sh
. "$(dirname -- "$0")/_/husky.sh"

# Run type checking first
yarn typecheck

# Run formatting and linting
"$(yarn bin)"/pretty-quick --staged
"$(yarn bin)"/lint-staged
```

**For Bun projects**:
```sh
#!/usr/bin/env sh
. "$(dirname -- "$0")/_/husky.sh"

# Run type checking first
bun run typecheck

# Run formatting and linting
bun run pretty-quick --staged
bun run lint-staged
```

#### Configure lint-staged in package.json

```json
{
  "lint-staged": {
    "*.{js,jsx,ts,tsx}": [
      "eslint --fix"
    ],
    "*.{json,md,mdx,css,html,yml,yaml}": [
      "prettier --write"
    ]
  }
}
```

This setup ensures that:
- TypeScript type checking runs first to catch type errors
- Code formatting is applied to staged files
- Linting rules are checked and fixed where possible
- Different commands are optimized for each package manager

#### Pre-push Hooks

For more rigorous checks before pushing to the remote repository, add a pre-push hook:

```bash
# Create a pre-push hook
pnpm exec husky add .husky/pre-push "pnpm run typecheck"
```

**For pnpm projects** (recommended):
```sh
#!/usr/bin/env sh
. "$(dirname -- "$0")/_/husky.sh"

# Run full type checking
pnpm run typecheck

# Optionally check formatting on files changed since main branch
git diff "origin/main" --diff-filter=ACM --name-only -z | xargs -0 $(pnpm bin)/prettier --ignore-unknown --check
```

**For npm projects**:
```sh
#!/usr/bin/env sh
. "$(dirname -- "$0")/_/husky.sh"

# Run full type checking
npm run typecheck

# Optionally check formatting on files changed since main branch
git diff "origin/main" --diff-filter=ACM --name-only -z | xargs -0 npx --no-install prettier --ignore-unknown --check
```

**For Yarn projects**:
```sh
#!/usr/bin/env sh
. "$(dirname -- "$0")/_/husky.sh"

# Run full type checking
yarn typecheck

# Optionally check formatting on files changed since main branch
git diff "origin/main" --diff-filter=ACM --name-only -z | xargs -0 "$(yarn bin)"/prettier --ignore-unknown --check
```

**For Bun projects**:
```sh
#!/usr/bin/env sh
. "$(dirname -- "$0")/_/husky.sh"

# Run full type checking
bun run typecheck

# Optionally check formatting on files changed since main branch
git diff "origin/main" --diff-filter=ACM --name-only -z | xargs -0 bun run prettier --ignore-unknown --check
```

The pre-push hook adds an extra layer of validation:
- Runs complete type checking across the entire codebase
- Verifies formatting on all files changed since the main branch
- Can be temporarily disabled with `git push --no-verify` when needed

#### Prepare Commit Message Hooks

Use prepare-commit-msg hooks to standardize commit messages with tools like Commitizen or to automatically prefix commits with JIRA issue keys.

**Commitizen Integration**:
```sh
#!/usr/bin/env sh
. "$(dirname -- "$0")/_/husky.sh"

# Skip during merge commits
if [ "$2" != "message" ] && [ "$2" != "merge" ]; then 
  exec < /dev/tty && $(pnpm bin)/cz --hook "$1" "$2" "$3" || true
fi
```

**JIRA Issue Key Integration (Basic)**:
```sh
#!/usr/bin/env sh
. "$(dirname -- "$0")/_/husky.sh"

# For pnpm
$(pnpm bin)/jira-prepare-commit-msg $1

# For npm
# npx --no-install jira-prepare-commit-msg $1

# For yarn
# yarn exec jira-prepare-commit-msg $1
```

**Advanced JIRA Integration (Without Dependencies)**:
```sh
#!/usr/bin/env sh
. "$(dirname -- "$0")/_/husky.sh"

# Automatically prepend the JIRA issue-key to the commit message
readonly COMMIT_MESSAGE_PATH="$1"
readonly COMMIT_TYPE="$2"

# Get current branch name, handling various git states
GIT_BRANCH=$(git branch --show-current || git rev-parse --abbrev-ref HEAD)
if [ -z "$GIT_BRANCH" ]; then
  REV_PARSE_PATH=$(git rev-parse --git-path rebase-merge)
  if test -d "${REV_PARSE_PATH}"; then
    REVISION=$(cat "${REV_PARSE_PATH}"/head-name)
    GIT_BRANCH=${REVISION##refs/heads/}
  fi
fi

# Don't proceed if branch name can't be determined
if [ -z "$GIT_BRANCH" ]; then
  echo "$(tput setaf 1)error$(tput sgr0) No branch found"
  exit 1
fi

# Skip for merge commits
if [ "$COMMIT_TYPE" = "commit" ] || [ "$COMMIT_TYPE" = "merge" ]; then
  exit
fi

# Extract JIRA issue key from branch name (format: PROJECT-123)
ISSUE_KEY=$(node -e 'console.log(process.argv.pop().split("/").reduce(((e,o)=>(o=/^[A-Z]{2,}-\d+/.exec(o)?.pop())?o:e),""));' "${GIT_BRANCH}")

# Skip if no issue key found
if [ -z "$ISSUE_KEY" ]; then
  echo "$(tput setaf 3)warning$(tput sgr0) No issue key found in branch '${GIT_BRANCH}'"
  exit
fi

# Skip if message already contains the issue key
if grep -q "^${ISSUE_KEY}\b" "$COMMIT_MESSAGE_PATH"; then
  exit
fi

# Prepend issue key to commit message
sed -i -e "1s/^/${ISSUE_KEY}: /" "$COMMIT_MESSAGE_PATH"
```

**Installation Steps**:

For Commitizen:
```bash
# Install Commitizen
pnpm add -D commitizen cz-conventional-changelog

# Configure in package.json
# {
#   "config": {
#     "commitizen": {
#       "path": "cz-conventional-changelog"
#     }
#   }
# }

# Add the prepare-commit-msg hook
pnpm exec husky add .husky/prepare-commit-msg "$(cat << 'EOF'
#!/usr/bin/env sh
. "$(dirname -- "$0")/_/husky.sh"

if [ "$2" != "message" ] && [ "$2" != "merge" ]; then 
  exec < /dev/tty && $(pnpm bin)/cz --hook "$1" "$2" "$3" || true
fi
EOF
)"
```

For JIRA integration:
```bash
# Option 1: Use jira-prepare-commit-msg package
pnpm add -D jira-prepare-commit-msg

# Add the prepare-commit-msg hook
pnpm exec husky add .husky/prepare-commit-msg "$(pnpm bin)/jira-prepare-commit-msg \$1"

# Option 2: Use the custom script (no dependencies)
# Copy the advanced script above to .husky/prepare-commit-msg
```

These hooks ensure:
- Standardized commit messages following conventional commits (with Commitizen)
- Automatic JIRA issue key detection from branch names
- Proper prefixing of commit messages with issue keys
- Graceful handling of edge cases like merge commits and branches without issue keys

### Syntax & Programming Style

- Use nullish coalescing (`??`) over logical OR (`||`) for default values.
- Prefer immutable programming and pure functions.
- Use appropriate error types (`TypeError`, `RangeError`, etc.).
- Add default case type checking in `switch` statements.

### Command Line

- **When generating code** (not editing existing), use **long flags**:
  - `--no-emit` instead of `-n`.
  - `prettier --write .` instead of `prettier -w .`.
  - `next lint --config eslint.config.mjs` instead of `next lint -c eslint.config.mjs`.
- Document shell scripts thoroughly.
- Name environment variables clearly.
- Use descriptive names for scripts in `package.json`.
- Use colorized output for warnings/errors.
- Use explicit exit codes for error conditions.

### Package Manager Selection

- **Prefer pnpm** over npm or Yarn for all projects when possible:
  - Superior disk space efficiency with content-addressable storage
  - Strict dependency resolution that prevents phantom dependencies
  - Built-in monorepo support with workspaces
  - Faster installation times
  - Most secure dependency resolution

- **Alternatively, use Bun** for projects needing maximum performance:
  - Extremely fast package installation
  - Built-in test runner and bundler
  - Native TypeScript support
  - Compatible with most npm packages

- **Setup for pnpm**:
  ```json
  // package.json
  {
    "packageManager": "pnpm@8.15.4"
  }
  ```
  
- **Lockfile guidance**:
  - Commit `pnpm-lock.yaml` or `bun.lockb` to version control
  - Never modify lockfiles manually
  - Update dependencies with `pnpm update` or appropriate commands
  - Run `pnpm install --frozen-lockfile` in CI environments

- **For existing projects**:
  - Do not switch package managers mid-project without full team agreement
  - When switching, delete the old lockfile and `node_modules` completely

### Node.js setup

#### Initial Setup

- **When initializing a new repository**, use LTS Node and create .nvmrc:
  ```bash
  # Switch to LTS version
  nvm use --lts
  
  # Create .nvmrc with current Node version
  node -v > .nvmrc
  ```

- **Always include `.nvmrc`** with the exact Node.js version to ensure consistency across development environments

#### Dynamic Version Management

- **Use `.nvmrc` to drive `package.json` settings** for CI/CD compatibility:
  ```json
  // package.json
  {
    "engines": {
      "node": ">=18.0.0",
      "pnpm": ">=8.0.0"
    },
    "packageManager": "pnpm@8"
  }
  ```

- For CI/CD pipelines, use dynamic version extraction:
  ```yaml
  # GitHub Actions workflow example
  jobs:
    build:
      runs-on: ubuntu-latest
      steps:
        - uses: actions/checkout@v4
        - name: Read .nvmrc
          run: echo "NODE_VERSION=$(cat .nvmrc)" >> $GITHUB_ENV
        - uses: actions/setup-node@v4
          with:
            node-version: ${{ env.NODE_VERSION }}
            cache: 'pnpm'
        - run: corepack enable
        - run: pnpm install --frozen-lockfile
  ```

- **Enforce Node.js version usage** in development with:
  ```bash
  pnpm exec check-node-version --package
  ```

- **When checking out a new codebase**, immediately look for and if necessary add:
  - `.nvmrc` for Node.js version management
  - `"packageManager"` field in package.json
  - Proper lockfile for the selected package manager

- Ensure `@types/node` is installed and matches the same Node.js version

### Monorepo Configuration

- Use **Turborepo** for monorepo workspaces that need advanced build optimizations:
  ```json
  // turbo.json
  {
    "$schema": "https://turbo.build/schema.json",
    "globalDependencies": ["tsconfig.json"],
    "pipeline": {
      "build": {
        "dependsOn": ["^build"],
        "outputs": [".next/**", "dist/**"]
      },
      "lint": {},
      "dev": {
        "cache": false,
        "persistent": true
      },
      "generate": {
        "dependsOn": [],
        "outputs": ["src/generated/**"]
      }
    }
  }
  ```

- For simpler monorepos, pnpm workspaces may be sufficient:
  ```json
  // pnpm-workspace.yaml
  packages:
    - 'apps/*'
    - 'packages/*'
  ```

- Configure shared dependencies carefully:
  - Use `"*"` for internal workspace packages
  - Pin exact versions for external packages in root
  - Consider `pnpm.overrides` for enforcing specific versions

### Code Generation

Prioritize automated code generation for schema-driven development. Include a `generate` script in package.json and run it as part of the build process.

#### Core Generation Tools

- **GraphQL Schema**: Use graphql-codegen for type-safe operations
  ```json
  {
    "scripts": {
      "generate": "graphql-codegen"
    }
  }
  ```

- **OpenAPI/Swagger**: Generate client-side types and API methods
  ```json
  {
    "scripts": {
      "generate": "openapi-codegen gen admin"
    }
  }
  ```

- **SVG Icons**: Transform SVGs into React components
  ```json
  {
    "scripts": {
      "generate": "svgr --icon --jsx-runtime automatic --out-dir src/generated/icons --ref --typescript -- icons"
    }
  }
  ```

- **CMS Integration**: Generate types from CMS schemas
  ```json
  {
    "scripts": {
      "generate": "sanity-codegen"
    }
  }
  ```

- **Blockchain/Custom APIs**: Use specialized generators
  ```json
  {
    "scripts": {
      "generate": "source .env; docker run -v .:/usr/app \"${CLI_IMAGE}\" chr generate-client-stubs --typescript"
    }
  }
  ```

#### Configuration Best Practices

- **Standardize Output Location**: Place all generated code in `src/generated/`
- **Gitignore Generated Files**: Add generated directories to `.gitignore` when appropriate
- **Version Config Files**: Always commit generator config files (e.g., `codegen.ts`)
- **Pre-Commit Hooks**: Run generators in pre-commit hooks or CI to ensure types stay current
- **Monorepo Setup**: Use Turborepo to orchestrate generation across workspaces
  ```json
  {
    "scripts": {
      "generate": "turbo run generate"
    }
  }
  ```

#### Generation Workflow

1. Define schemas/APIs first (contract-first development)
2. Configure generators to create type-safe interfaces
3. Implement features using the generated types
4. Run generation on schema changes
5. Validate generated output is type-compatible with existing code

#### Key Tools Configuration

- **GraphQL Codegen**:
  ```typescript
  // codegen.ts
  export default {
    schema: "schema.graphql",
    documents: ["src/**/*.graphql"],
    generates: {
      "src/generated/graphql.ts": {
        plugins: ["typescript", "typescript-operations", "typescript-react-query"],
        config: {
          fetcher: "@/lib/graphql-fetcher#fetchData",
          enumsAsTypes: true
        }
      }
    }
  };
  ```

- **OpenAPI Codegen**:
  ```typescript
  // openapi-codegen.config.ts
  import { defineConfig } from "@openapi-codegen/cli";
  import { generateSchemaTypes, generateReactQueryComponents } from "@openapi-codegen/typescript";
  
  export default defineConfig({
    admin: {
      from: { source: "url", url: "https://api.example.com/schema.json" },
      outputDir: "src/generated/admin",
      to: async (context) => {
        const filenamePrefix = "adminApi";
        const clients = await generateReactQueryComponents(context, {
          filenamePrefix,
          clientName: "AdminApi"
        });
        const schemas = await generateSchemaTypes(context, { filenamePrefix });
        return [...clients, ...schemas];
      }
    }
  });
  ```

### `package.json` Scripts

Include (or ensure you have) scripts for:

- `build`
- `dev`
- `format`
- `lint`
- `prepare`
- `spellcheck`
- `start`
- `typecheck`

Example snippet to add if missing:

```json
{
  "scripts": {
    "lint": "eslint --cache",
    "format": "prettier --write .",
    "prepare": "husky",
    "spellcheck": "cspell --config=cspell.json \"**/*.{cjs,js,md,mjs,ts,tsx}\" --no-progress --show-context --show-suggestions",
    "typecheck": "tsc --noEmit"
  }
}
```

### Spell Checking Configuration

Always include a `cspell.json` file in the project root to ensure consistent spell checking across the team and in CI/CD pipelines.

```json
// cspell.json
{
  "$schema": "https://raw.githubusercontent.com/streetsidesoftware/cspell/main/cspell.schema.json",
  "version": "0.2",
  "language": "en",
  "useGitignore": true,
  "allowCompoundWords": true,
  "ignorePaths": [
    // Dependencies
    "node_modules",
    // Build outputs
    "dist",
    ".next",
    "build",
    // Generated files
    "src/generated/**",
    "**/generated/**",
    // Large binary or lock files
    "pnpm-lock.yaml",
    "yarn.lock",
    "package-lock.json",
    "bun.lockb",
    "*.min.*",
    "*.mp4",
    "*.webm",
    "*.glb",
    // Environment and configuration
    ".env",
    ".env.*",
    // Test files (customize as needed)
    "*.test.*",
    "*.spec.*",
    "*.cy.*",
    "*.stories.*",
    "**/__fixtures__",
    "**/cypress",
    "**/fixtures",
    "**/test-data"
  ],
  "ignoreRegExpList": [
    // Escape sequences
    "\\\\(.*\\\\)",
    // Comments
    "\\/\\*[\\s\\S]*?\\*\\/",
    // Template literals
    "\\{\\{[\\s\\S]*?\\}\\}",
    // Possessives
    "//'s+",
    // File extensions
    "\\w+\\.\\w+",
    // Import statements
    "import\\s+.+?\\s+from\\s+'.*'",
    // Hash patterns and long identifiers
    "[a-f\\d]{32,}",
    // Data URIs
    "data:([a-z]+/[a-z0-9-+.]+);base64,([A-Za-z0-9+/=])"
  ],
  "words": [
    // Package managers & build tools
    "pnpm",
    "lerna",
    "turborepo",
    "vite",
    "tsup",
    "esbuild",
    "rollup",
    "npmrc",
    "nvmrc",
    
    // Frameworks & libraries
    "nextjs",
    "preact",
    "svelte",
    "astro",
    "qwik",
    "fastify",
    "nestjs",
    "trpc",
    "tanstack",
    "zustand",
    "xstate",
    "jotai",
    "valtio",
    "immer",
    "zod",
    "viem",
    "wagmi",
    "ethers",
    "gsap",
    "framer",
    "shadcn",
    "tailwindcss",
    
    // UI libraries & components
    "lucide",
    "heroicons",
    "radix",
    "mantine",
    "chakra",
    "headlessui",
    "vaul",
    "sonner",
    "contentful",
    "storybook",
    "nextui",
    "swiper",
    "clsx",
    "clsxm",
    "cva",
    "cmdk",
    
    // Testing & tooling
    "vitest",
    "uvu",
    "jest",
    "cypress",
    "testid",
    "lcov",
    "codecov",
    "typecheck",
    "tsbuildinfo",
    "codemod",
    "svgr",
    "rehype",
    "shiki",
    
    // Web3 & blockchain
    "secp256k1",
    "merkle",
    "chromia",
    "rell",
    "brid",
    "brids",
    "dapp",
    "dapps",
    "promievent",
    "gtxclient",
    "secp",
    "ierc",
    "dalarnia",
    "hbridge",
    
    // File formats & data
    "webp",
    "avif",
    "webm",
    "jsonld",
    "superjson",
    "toml",
    "yaml",
    "graphql",
    "openapi",
    "camelcase",
    "kebabcase",
    "dataurl",
    
    // Auth & identity
    "supabase",
    "oauth",
    "oidc",
    "jwks",
    "cognito",
    "signin",
    "signup",
    "signout",
    "onboarded",
    
    // Payment providers
    "klarna",
    "vipps",
    "stripe",
    "paypal",
    "gtin13",
    
    // Analytics & tracking
    "gtag",
    "matomo",
    "plausible",
    "mixpanel",
    "metrica",
    "ganalytics",
    
    // Deployment & hosting
    "vercel",
    "netlify",
    "cloudflare",
    "amazonaws",
    "digitalocean",
    "heroku",
    
    // Development patterns
    "memoize",
    "debounce",
    "throttle",
    "middleware",
    "middlewares",
    "codegen",
    "codebase",
    "monorepo",
    "vendored",
    "treeshake",
    "transpile",
    "polyfill",
    "esbuild"
  ],
  "overrides": [
    {
      "filename": "**/locales/sv/**/*.json",
      "language": "en,sv" 
    },
    {
      "filename": "**/locales/de/**/*.json",
      "language": "en,de"
    }
  ],
  "import": []
}
```

#### Key Configuration Features

- **Comprehensive Technical Dictionary**: Over 100 commonly used technical terms pre-approved and categorized by domain
- **Multi-Language Support**: Configuration for projects with internationalization (Swedish, German, etc.)
- **Smart Ignores**:
  - Generated code (all common output directories)
  - Build artifacts and bundle files
  - Environment and configuration files
  - Test fixtures and mock data
  - Binary and media files
  - Lock files from all package managers

- **RegExp Pattern Ignores**: Common code patterns that frequently trigger false positives:
  - Import statements
  - File paths with extensions
  - Long hashes and cryptographic identifiers
  - Base64 data URIs
  - Template literals
  - Code comments with non-dictionary terms

- **Optimized for Modern Workflows**:
  - Blockchain/Web3 terminology
  - Frontend frameworks and libraries
  - Testing and tooling identifiers
  - Payment providers
  - Authentication systems

#### Implementation

1. Place `cspell.json` in the project root directory
2. Configure the spell checking script in package.json:
   ```json
   "scripts": {
     "spellcheck": "cspell --config=cspell.json \"**/*.{ts,tsx,js,jsx,md,mdx}\" --no-progress"
   }
   ```
3. Add to pre-commit hooks or CI pipeline
4. Extend with domain-specific terms as needed

For projects with non-English content or documentation, add the appropriate language dictionaries:

```bash
pnpm add -D @cspell/dict-sv @cspell/dict-de-de
```

Then update the imports section of cspell.json:
```json
"import": [
  "@cspell/dict-sv/cspell-ext.json",
  "@cspell/dict-de-de/cspell-ext.json"
]
```

### `tsconfig.json`

- Use `@tsconfig/strictest`.
- Also use `@tsconfig/nodeXX` (replace XX with your Node version).
- Use `@tsconfig/next` if you're on Next.js.

**Example** (Next.js):

```json
{
  "extends": [
    "@tsconfig/strictest/tsconfig.json",
    "@tsconfig/next/tsconfig.json"
  ],
  "compilerOptions": {
    "baseUrl": ".",
    "paths": { "@/*": ["./*"] }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules"]
}
```

### ESLint Configuration

Use ESLint's new flat config format with the following plugins and configurations. This setup enforces code quality, React best practices, and TypeScript correctness.

#### Essential Plugins

```bash
# Core and TypeScript
npm install -D eslint @eslint/js typescript-eslint @typescript-eslint/parser

# React and Next.js
npm install -D eslint-plugin-react eslint-plugin-react-hooks eslint-plugin-react-refresh @next/eslint-plugin-next

# Import management
npm install -D eslint-plugin-import-x eslint-plugin-simple-import-sort eslint-plugin-unused-imports

# Other quality tools
npm install -D eslint-plugin-promise @tanstack/eslint-plugin-query eslint-plugin-react-compiler
```

#### Configuration Structure (`eslint.config.js`)

Use ESLint's flat config format with modular configuration:

```js
// eslint.config.js
import js from "@eslint/js";
import nextPlugin from "@next/eslint-plugin-next";
import pluginQuery from "@tanstack/eslint-plugin-query";
import tsParser from "@typescript-eslint/parser";
import eslintPluginImportX from "eslint-plugin-import-x";
import pluginPromise from "eslint-plugin-promise";
import react from "eslint-plugin-react";
import reactCompiler from "eslint-plugin-react-compiler";
import reactHooks from "eslint-plugin-react-hooks";
import reactRefresh from "eslint-plugin-react-refresh";
import simpleImportSort from "eslint-plugin-simple-import-sort";
import unusedImports from "eslint-plugin-unused-imports";
import globals from "globals";
import { config as tsEslintConfig, configs as tsEslintConfigs } from "typescript-eslint";

// Config implementation
export default tsEslintConfig(
  // Base configurations
  // TypeScript configurations 
  // Plugin configurations
  // File-specific overrides
);
```

#### Plugin Purposes

- **TypeScript Integration**: 
  - `typescript-eslint` - Strict type checking rules
  - `@typescript-eslint/parser` - Enables ESLint to understand TypeScript

- **React Best Practices**:
  - `eslint-plugin-react` - Core React patterns (component definition, prop naming)
  - `eslint-plugin-react-hooks` - Enforces Rules of Hooks
  - `eslint-plugin-react-refresh` - Optimizes for Fast Refresh compatibility
  - `eslint-plugin-react-compiler` - Ensures compatibility with React Compiler (Forget)

- **Import Management**:
  - `eslint-plugin-import-x` - Import validation and restrictions
  - `eslint-plugin-simple-import-sort` - Consistent import ordering
  - `eslint-plugin-unused-imports` - Automatic removal of unused imports

- **Framework Specific**:
  - `@next/eslint-plugin-next` - Next.js best practices and patterns
  - `@tanstack/eslint-plugin-query` - TanStack Query optimization rules

- **Code Quality**:
  - `eslint-plugin-promise` - Promise handling best practices

#### Key Rule Configurations

- **TypeScript Strictness**:
  - Enforced nullish coalescing over logical OR
  - Consistent type definitions (`type` over `interface`)
  - Proper type imports

- **React Patterns**:
  - Boolean prop naming convention (`isX`, `hasX`, `showX`)
  - Self-closing component enforcement
  - JSX prop sorting
  - Component definition style consistency
  - Prevention of unstable nested components

- **Import Organization**:
  - Grouping imports by source type (React, Next.js, node_modules, local)
  - Automatic removal of unused imports
  - Type import separation

- **Framework Conventions**:
  - Exceptions for Next.js page components
  - Special rules for UI component libraries
  - Prevention of direct Radix UI imports outside UI components

#### Implementation Notes

- Use `"react/boolean-prop-naming"` to enforce consistent boolean prop names
- Configure `"react/jsx-sort-props"` for consistent prop ordering
- Implement `"simple-import-sort/imports"` with custom grouping
- Use file overrides to exempt certain files from specific rules
- Enable React compiler checks for better performance
- Add specialized rules for UI components directory

## Technology-Specific Standards

### TypeScript

- Leverage **discriminated unions** for state variations.
- Use `as const` to preserve literal types.
- Prefer `satisfies` over `as` for safer type compatibility.
- Default to `type` for local/complex unions, and `interface` for public or extendable contracts.
- Avoid `any`, `as`, and `is`; use `zod` for strict type checks.
- Employ utility types (`Partial`, `Pick`, `Omit`, etc.).
- Use the strictest TS config available.

### Tailwind CSS & ShadCN

- Use `import { cn } from "@/lib/utils";` to merge conditional classes.
- **Never** build class names with string concatenation.
- **Avoid inline styles**; rely on Tailwind or `class-variance-authority`.
- Extend Tailwind config for design tokens and to avoid "magic numbers."
- Use **ShadCN** CSS variables for consistent theming (e.g., `bg-primary text-primary-foreground`).
- Use `cva` from `class-variance-authority` to handle component styling variations.
- Example styling pattern:

```tsx
const componentVariants = cva(
  "base-styles-here",
  {
    variants: {
      variant: {
        default: "variant-specific-styles",
        secondary: "secondary-variant-styles",
      },
      size: {
        sm: "small-size-styles",
        md: "medium-size-styles",
        lg: "large-size-styles",
      },
    },
    defaultVariants: {
      variant: "default",
      size: "md",
    },
  },
);
```

### React

- For props, define a `[ComponentName]Props` type.
- Don't inline `children` in the props type; use `PropsWithChildren`.
- **Custom Hooks** should do one job well, with consistent return signatures.
- Avoid `useEffect` for data fetching or side effects.
- Use `"use client"` directive at the top of all interactive components.
- Mark all components that use hooks or browser APIs with `"use client"`.
- Keep components focused on a single responsibility.
- Extract complex logic to custom hooks.

### React Hooks

- For async, **avoid** `useEffect` or `useCallback`; prefer react-query's `useQuery`/`useMutation`.

### Form Handling

- Always use **react-hook-form**.
- Integrate Zod resolvers for runtime validation.
- **ALWAYS** use the `useTypedForm` helper function from `@/lib/form` to create type-safe forms:

```ts
import { useForm } from "react-hook-form";
import { zodResolver } from "@hookform/resolvers/zod";

export const useTypedForm = <T extends z.ZodType>({
  zodSchema,
  defaultValues,
}: {
  zodSchema: T;
  defaultValues: z.infer<T>;
}) => {
  return useForm<z.infer<T>>({
    resolver: zodResolver(zodSchema),
    defaultValues,
  });
};
```

- **ALWAYS** use the `getTypedFields` helper to create strongly-typed form fields:

```ts
export function getTypedFields<T extends z.ZodType>(
  fields: Record<keyof z.infer<T>, React.ReactNode>
) {
  return fields;
}
```

#### Standard Form Input Components

**ALWAYS** use the standardized input components from `@/components/form-input`:

- `FormInput` - For standard text inputs
- `FormTextarea` - For multi-line text inputs
- `FormSelect` - For dropdown selection
- `FormMultiSelect` - For multiple item selection
- `FormCheckbox` - For boolean values
- `EmotionSlider` - For emotional trait sliders
- `DatePicker` - For date selection

Example input usage:

```tsx
// Standard text input
<FormInput
  field={field}
  label="Name"
  placeholder="Enter name"
  type="name"
/>

// Multi-select example
<FormMultiSelect
  field={field}
  label="Knowledge Bricks"
  options={knowledgeBricks.map((brick) => ({
    value: brick.id.toString(),
    label: brick.title,
  }))}
  placeholder="Select knowledge bricks"
  type="knowledge_bricks"
/>

// Emotion slider example
<EmotionSlider
  field={field}
  label="Joy-Sadness"
  labelCenter="Neutral"
  labelEnd="Joy"
  labelStart="Sadness"
  max={1}
  min={-1}
  type="joy_sadness"
/>
```

#### Type-Safe Form Implementation Pattern

```tsx
// 1. Import required hooks and components
import { schemas } from "@/generated/schemas";
import { getTypedFields, useTypedForm } from "@/lib/form";

// 2. Define component props
export function CreateEntityForm({
  relatedData
}: {
  relatedData: RelatedData[]
}) {
  // 3. Get mutation hook
  const { mutateAsync: createEntity } = useCreateEntityMutation();

  // 4. Define schema and default values
  const zodSchema = schemas.EntityCreate;
  const defaultValues = {
    name: "",
    description: "",
    // All fields from the schema should have defaults
  };

  // 5. Initialize form with useTypedForm
  const form = useTypedForm({ zodSchema, defaultValues });

  // 6. Define fields with getTypedFields
  const fields = getTypedFields<typeof zodSchema>({
    name: (
      <FormField
        control={form.control}
        name="name"
        render={({ field }) => (
          <FormInput
            field={field}
            label="Name"
            placeholder="Enter name"
            type="name"
          />
        )}
      />
    ),
    // Define all fields in the schema
  });

  // 7. Implement form submission
  return (
    <Form {...form}>
      <form
        className="space-y-4"
        onSubmit={form.handleSubmit(async (values) => {
          try {
            const result = await createEntity(values);
            toast.success("Entity created successfully");
            // Handle success (navigation, etc.)
          } catch (error) {
            toast.error("Failed to create entity");
            console.error(error);
          }
        })}
      >
        {/* 8. Render fields */}
        <div className="grid grid-cols-2 gap-4">
          {fields.name}
          {fields.description}
          {/* Other fields */}
        </div>

        <Button type="submit">Create Entity</Button>
      </form>
    </Form>
  );
}
```

#### Multi-Step Forms

For complex forms that require multiple steps:

1. Use the Tabs component to organize content into logical sections
2. Implement section validation to control navigation between tabs
3. Store active section state with React's useState
4. Add navigation controls (Next/Back buttons)
5. Implement conditional rendering for sections
6. Consider adding a preview step before final submission

Multi-step forms should follow the pattern established in `CreateCharacterForm` with validation for each section and a final preview before submission.

#### Working with Generated Schemas

The `schemas.ts` file is automatically generated from the backend API using:

```bash
pnpm generate
```

When backend schemas evolve:

1. Run the generate script to update `schemas.ts`
2. Update form `defaultValues` to include any new fields
3. Add new fields to the `getTypedFields` object
4. Implement appropriate input components for new fields
5. Update form validation and submission logic if needed

**IMPORTANT**: Never manually modify the generated `schemas.ts` file; always regenerate it from the API.

### Zod

- **Always** validate incoming data with Zod (API, `unknown`, `any`, etc.).
- Use `.passthrough()` or `.object()` if extra props are acceptable.
- For array schemas, define a separate item schema.
- Provide sensible validation (e.g., non-empty strings, correct numeric ranges).
- Use **camelCase** for schema names:
  ```ts
  export const userResponseSchema = z.strictObject({ ... });
  export type UserResponse = z.infer<typeof userResponseSchema>;
  ```
- Recommend `z.strictObject`, but allow `.passthrough()` if needed.
- Use `z.infer` and **export** those types.
- For advanced validation, use `.refine()`, `.transform()`, `.lazy()`, and schema merging.

### @tanstack/react-query@5

#### General Best Practices

- **NEVER** place `useQuery` or `useMutation` inside a component. Keep them in module scope.
- Use `queryKey`/`mutationKey` for precise cache invalidation.
- Use `select` to transform data for the UI.
- Invalidate queries when mutations affect cached data.
- Keep fetchers and transformers separate from query hooks:
  ```ts
  export const useUsersQuery = () =>
    useQuery({
      queryKey: ["users"],
      queryFn: getUsers,
      select: transformUsers,
    });
  ```
- Use `onSettled`, `onSuccess`, `onError` for mutation/query lifecycle.
- Configure `QueryCache`/`MutationCache` centrally (with Sentry if needed).
- Give hooks descriptive names like `useGetMemeCoinPriceQuery`.
- Match `queryKey` to your named operation plus arguments (e.g., `["get_meme_coin_price", tokenId]`).

#### Cache Invalidation on Authentication State Changes

Implement global query cache invalidation on login/logout to maintain data isolation between user sessions:

```tsx
const useAuth = () => {
  const authStore = useAuthStore();
  const queryClient = useQueryClient();

  return {
    ...authStore,
    setAuth: (auth: AuthState) => {
      authStore.setAuth(auth);
      // Clear cache on successful authentication
      if (auth.isAuthenticated) {
        void queryClient.invalidateQueries();
      }
    },
    logout: () => {
      // Clear cache before session termination
      void queryClient.invalidateQueries();
      authStore.logout();
    },
  };
};
```

This comprehensive cache invalidation strategy is more robust than adding user-specific identifiers to individual query keys. It guarantees complete cache purging during authentication state transitions, eliminating the risk of data leakage between sessions. While an alternative approach would be incorporating session identifiers into all query keys, such implementation would require perfect consistency across the codebase. The global invalidation pattern provides stronger security guarantees with minimal performance impact, as the subsequent requests would be necessary regardless when changing users.

#### React Query Pattern Implementation

All data operations should use TanStack Query (react-query). Implement API operations following this pattern:

```tsx
// 1. Query implementation
export function useGetEntitiesQuery() {
  return useQuery({
    queryKey: ["entities"],
    queryFn: async () => {
      const response = await apiClient.getEntities();
      return schemas.EntitiesResponse.parse(response);
    },
  });
}

// 2. Query with parameters
export function useGetEntityQuery(id: string) {
  return useQuery({
    queryKey: ["entity", id],
    queryFn: async () => {
      const response = await apiClient.getEntity(id);
      return schemas.EntityResponse.parse(response);
    },
    enabled: Boolean(id),
  });
}

// 3. Mutation implementation
export function useCreateEntityMutation() {
  const queryClient = useQueryClient();

  return useMutation({
    mutationFn: async (data: z.infer<typeof schemas.EntityCreate>) => {
      const response = await apiClient.createEntity(data);
      return schemas.EntityResponse.parse(response);
    },
    onSuccess: () => {
      // Invalidate relevant queries to refresh data
      queryClient.invalidateQueries({ queryKey: ["entities"] });
      toast.success("Entity created successfully");
    },
    onError: (error) => {
      console.error(error);
      toast.error("Failed to create entity");
    },
  });
}
```

**Key Requirements:**

1. **Always validate responses with Zod schemas**
2. **Use queryKey consistently** for effective cache invalidation
3. Export hooks with descriptive names following the pattern:
   - `use[Action][Entity][Query|Mutation]`
4. Include proper error handling within the mutation/query
5. Handle dependent queries with the `enabled` option
6. Group related queries together
7. For optimistic updates, use `onMutate` to update the cache immediately

### API Integration

- Prefer `axios` with a config object (headers, base URL).
- **Always** validate responses with Zod.
- Separate API logic from UI.
- Avoid `fetch`; wrap logic in react-query hooks.
- Use generated API clients where possible.
- Handle authentication and error states consistently.
- Structure endpoints by entity and functionality.
- Use typing that corresponds to API schemas.
- Centralize API configuration.

### State Management

- Use Zustand for global application state.
- Use localStorage persistence when appropriate.
- Validate with Zod when hydrating from storage.
- Apply immutable update patterns.
- Derive complex state when possible instead of storing it.
- Keep stores small and focused.

### Utility Functions

- Keep them pure, well-typed, and documented.
- Use descriptive names and proper error handling.

### Modals with @ebay/nice-modal-react

Use `@ebay/nice-modal-react` for all modal management. Implementation pattern:

1. Define a modal component:

```tsx
import NiceModal, { useModal } from '@ebay/nice-modal-react';

export const MyModal = NiceModal.create(({ title, description }: { title: string; description: string }) => {
  const modal = useModal();

  return (
    <Dialog
      open={modal.visible}
      onOpenChange={(open) => {
        if (!open) modal.hide();
      }}
    >
      <DialogContent>
        <DialogHeader>
          <DialogTitle>{title}</DialogTitle>
          <DialogDescription>{description}</DialogDescription>
        </DialogHeader>
        <div className="flex justify-end gap-2">
          <Button variant="outline" onClick={() => modal.hide()}>Cancel</Button>
          <Button onClick={() => modal.resolve(true)}>Confirm</Button>
        </div>
      </DialogContent>
    </Dialog>
  );
});
```

2. Create a hook to handle modal state:

```tsx
// src/app/users/use-create-user-modal.tsx
import NiceModal from '@ebay/nice-modal-react';
import { MyModal } from '@/components/my-modal';

export function useMyModal() {
  const showMyModal = async (title: string, description: string) => {
    const result = await NiceModal.show(MyModal, { title, description });
    return result as boolean;
  };

  return { showMyModal };
}
```

3. Use the modal in a component:

```tsx
function MyComponent() {
  const { showMyModal } = useMyModal();

  const handleShowModal = async () => {
    const confirmed = await showMyModal('Confirm Action', 'Are you sure you want to proceed?');
    if (confirmed) {
      // Handle confirmation
    }
  };

  return <Button onClick={handleShowModal}>Show Modal</Button>;
}
```

### Routing and Navigation

- File-based routing with Next.js App Router
- Protected routes with authentication checks
- Query parameters for dynamic data filtering
- Consistent navigation patterns
- Programmatic navigation with useRouter

For static exports:
- Use query parameters instead of dynamic routes for data filtering and selection
- Avoid server-side redirects or middleware
- All dynamic data must be fetched client-side after route hydration
- Prefer shallow routing with query parameters for state changes

### Authentication and Authorization

- JWT-based authentication
- Protected route HOC pattern
- Role-based access control
- Persistent auth state
- Automatic handling of auth errors

Implementation pattern:

```tsx
// src/components/protected-route.tsx
export function ProtectedRoute({
  children,
  requiredRole,
}: {
  children: ReactNode;
  requiredRole?: UserRole;
}) {
  const { isAuthenticated, user, isLoading } = useAuth();
  const router = useRouter();

  useEffect(() => {
    if (!isLoading && !isAuthenticated) {
      router.push('/login');
    } else if (requiredRole && user?.role !== requiredRole) {
      router.push('/unauthorized');
    }
  }, [isAuthenticated, isLoading, user, router, requiredRole]);

  if (isLoading) {
    return <LoadingSpinner />;
  }

  if (!isAuthenticated) {
    return null;
  }

  if (requiredRole && user?.role !== requiredRole) {
    return null;
  }

  return <>{children}</>;
}
```

### Error Handling

- Use typed error formatters.
- Provide specific, helpful messages.
- Employ error boundaries when appropriate.
- Use toast notifications for user feedback.
- Log errors with appropriate context.
- Provide specific error messages.
- Implement error boundaries for critical UI sections.
- Handle API errors consistently.
- Validate data at all trust boundaries.
- Check for edge cases like empty arrays, null values.

### Configuration Management

- Use typed configs for environment variables (e.g., `@t3-oss/env-nextjs`).
- Never call `process.env` directly.

## Integration with Specific Technologies

### Chromia Postchain

1. **Use Zod** for validating all responses.
2. **Leverage react-query** for caching and data management.
3. **Group** queries/mutations by feature.
4. **Handle errors** with a centralized `QueryCache` and consider logging to Sentry.

### Common libraries
- `@chromia/ft4`, `postchain-client` for Chromia
- For Ethereum/multi-chain: `connectkit`, `wagmi` (built on `viem`)

## Implementation Process

1. **Planning Phase**
   - Define the feature scope, requirements, and acceptance criteria
   - Identify affected components, data structures, and API endpoints
   - Break down work into manageable chunks
   - Define necessary schema extensions

2. **Implementation Phase**
   - Work incrementally on small chunks
   - Maintain consistent coding style
   - Adhere to the standards in this document
   - Test as you build

3. **Review and Test Phase**
   - Validate against acceptance criteria
   - Ensure type safety across the implementation
   - Test error states and edge cases
   - Verify responsive behavior

4. **Finalization Phase**
   - Complete documentation
   - Fix any remaining issues
   - Prepare for code review
   - Ensure all tests pass
   - Verify build process success

## Performance Considerations

- Use React Query's caching capabilities for optimal client-side data management
- Implement appropriate component memoization to reduce unnecessary renders
- Use code splitting and lazy loading for improved initial load times
- Optimize images and assets for static delivery
- Apply appropriate bundle optimizations for minimal output size
- Pre-compute and inline critical data where possible
- Avoid unnecessary re-renders through proper component design
- Consider static generation strategies for data-heavy pages
- Use proper cache headers for deployed static assets

## Security Best Practices

- Never store sensitive data in client-side state or localStorage
- Implement proper token refresh and expiration handling
- All authentication and authorization must happen appropriately
- Use session storage for temporary sensitive data when necessary
- Apply proper authorization checks for UI rendering
- Sanitize all user-generated content before rendering
- Follow OWASP security guidelines
- Use environment variables appropriately
- Consider security implications of exposing API endpoints
- Implement proper CORS configuration on backend services

## Conclusion

By combining these **Front-End Coding Best Practices** with the **chunking and iterative approach** for large features, you empower Cursor's Composer to operate effectively on **new** or **existing** codebases, avoiding context window limits and ensuring that each subtask is validated and integrated properly. Remember to:

- **Break down** large tasks into subtasks.
- **Carry over context** explicitly when prompting.
- **Validate** each chunk with tests and user feedback.
- **Finalize** once all chunks align with `.cursorrules`.

This approach helps maintain a coherent, type-safe, and maintainable codebase while systematically leveraging Cursor's capabilities.
